---
title: "combined_data"
author: "SK"
date: "12/05/2021"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
# inporting all the libraries
library(plyr)
library(dplyr)
library(caret)
library(ggplot2)
library(repr)
library(glmnet)
knitr::opts_chunk$set(echo = FALSE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
combined_data <- read.csv("combined_data.csv")
```

# dimensions of the dataframe

```{r}
dim(combined_data)
```

# Exploratory data analysis

```{r}
length(names(combined_data))
```

# If you need to find out which columns you are having na. just give the code as... colnames(is.na(data_name))
# If you need to find out how many na's are there in the whole dataset... sum(is.na(data_name))

```{r}

sum(is.na(combined_data))
is.null(combined_data) 

```

# for Amikacin

# The density plot provides a visual judgment about whether the distribution is bell shaped.
```{r}
ggdensity(combined_data$Mean_Amikacin, 
          main = "Density plot of Mean_Amikacin",
          xlab = "Mean_Amikacin")
```

# Q-Q plot: Q-Q plot (or quantile-quantile plot) draws the correlation between a given sample and the normal distribution. 
  # A 45-degree reference line is also plotted.

```{r}
ggqqplot(combined_data$Mean_Amikacin, 
         main = "QQ plot of Mean_Amikacin",
         xlab = "Mean_Amikacin")
```


# for Ofloxacin

```{r}
ggdensity(combined_data$Mean_Ofloxacin, 
          main = "Density plot of Mean_Ofloxacin",
          xlab = "Mean_Ofloxacin")

```


```{r}
ggqqplot(combined_data$Mean_Ofloxacin, 
         main = "QQ plot of Mean_Ofloxacin",
         xlab = "Mean_Ofloxacin")
```

# Initiating the splitting of data 

# Note: the genes are present from columns 3:16385 of the dataframe

```{r}
#split_data
set.seed(123)
nrow <- nrow(combined_data)
ncol <- ncol(combined_data)
spliter_8 <- as.integer(nrow*0.8)

x_train = combined_data[1:spliter_8, 1:(ncol-2)]
x_train
```

```{r}
#split_data
ofloxacin_train = combined_data$Mean_Ofloxacin[1:spliter_8]
amikacin_train = combined_data$Mean_Amikacin[1:spliter_8]
str(amikacin_train)
str(ofloxacin_train)
```

```{r}
#split_data
x_test = combined_data[(spliter_8+1):nrow,1:(ncol-2)]
x_test
```

```{r}
#split_data
ofloxacin_test <- combined_data$Mean_Ofloxacin[(spliter_8+1):nrow]
amikacin_test <- combined_data$Mean_Amikacin[(spliter_8+1):nrow]
str(amikacin_test)
str(ofloxacin_test)
```
# for Mean_Amikacin analysis execute this block

```{r}

temp_train <- amikacin_train
temp_test <- amikacin_test
temp_name <- 'Mean_Amikacin'
```

# for Mean_Ofloxacin analysis execute this block

```{r}

temp_train <- ofloxacin_train
temp_test <- ofloxacin_test
temp_name <- 'Mean_Ofloxacin'
```

# Linear regression model

```{r}

# linear regression model
model <- lm(combined_data[])
summary(model)
```


# Finding the optimal lambda value

```{r}


lambdas <- 10^seq(2, -3, by = -.1)

# Setting alpha = 1 implements lasso regression
lasso_reg <- cv.glmnet(data.matrix(x_train), temp_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 5)

# Best 
lambda_best <- lasso_reg$lambda.min 
lambda_best
plot(lasso_reg)
```

# Training the lasso model 

```{r}
lasso_model <- glmnet(data.matrix(x_train), temp_train, alpha = 1, lambda = lambda_best, standardize = TRUE)
print(lasso_model)

# The negative value of R-square shows that the chosen model does not follow the trend of the data so it fits worse than horizontal line 
```




# Generating the predictions and printing the evaluation metrics test datasets
```{r}
set.seed(23)
# evaluation function
eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - (SSE / SST)
  RMSE = sqrt(SSE/nrow(df))
  # Model performance metrics
  data.frame(RMSE = RMSE, R_square = R_square)
}

# prediction of x_test to campare the results with y_test
predictions_test <- predict(lasso_model, s = lambda_best, newx = data.matrix(x_test))

eval_results(temp_test, predictions_test, x_test)
```

# Generating the predictions and the actual data in the same data frame

```{r}
#create data frame with a column of actual values and a column of predicted values
data <- data.frame(pred = predictions_test, actual = amikacin_test)
data
```

# Calculating the MSE

```{r}
# Calculate MSE
mean((data$actual - data$X1)^2)
```
# Calculating mean absolute error (MAE)

```{r}
# Calculating MAE
mae(data$X1, data$actual)

```

# Defining the function to plot the spearman plot correlation

```{r}

spearman.plot <- function(x, y=NULL,dcol="blue", lhist=20, num.dnorm=5*lhist, plot.cor = TRUE,...){
	if (!is.null(y)){
		x = cbind(x,y)
	}

	### omit missing vars
	missing.vals = which(is.na(rowSums(x)))
	if (length(missing.vals)>0){
		x = x[-missing.vals,]
	}

	if (ncol(x)!=2 & is.null(y)){
		stop("You must supply either a nx2 matrix, or a y vector")
	}
	 
    ## set up layout and graphical parameters
    layMat <- matrix(c(2,0,1,3), ncol=2, byrow=TRUE)
    layout(layMat, widths=c(5/7, 2/7), heights=c(2/7, 5/7))
    ospc <- 0.5 # outer space
    pext <- 2 # par extension down and to the left
    bspc <- 1 # space between scatter plot and bar plots
    par. <- par(mar=c(pext, pext, bspc, bspc),
                oma=rep(ospc, 4)) # plot parameters
 
    ## scatter plot
    par(mar=c(3, 3, 1, 1), mgp=c(1.5, .35, 0), tck=-.01, cex.axis=.8)    
    plot(apply(x, 2, rank), ...)
    abline(lm(rank(x[,2])~rank(x[,1])))    
    
   	#### make axis labels
	#axis(1, at=quantile(rank(x[,1])), labels=round(quantile(x[,1]), digits=2))
	#axis(2, at=quantile(rank(x[,2])), labels=round(quantile(x[,2]), digits=2))

    ## determine barplot and height parameter
    ## histogram (for barplot-ting the density)
    xhist <- hist(x[,1], plot=FALSE, breaks=seq(from=min(x[,1]), to=max(x[,1]),
                                     length.out=lhist))
    yhist <- hist(x[,2], plot=FALSE, breaks=seq(from=min(x[,2]), to=max(x[,2]),
                                     length.out=lhist)) # note: this uses probability=TRUE
    ## determine the plot range and all the things needed for the barplots and lines
    xx <- seq(min(x[,1]), max(x[,1]), length.out=num.dnorm) # evaluation points for the overlaid density
    xy <- dnorm(xx, mean=mean(x[,1]), sd=sd(x[,1])) # density points
    yx <- seq(min(x[,2]), max(x[,2]), length.out=num.dnorm)
    yy <- dnorm(yx, mean=mean(x[,2]), sd=sd(x[,2]))
    ## barplot and line for x (top)
    par(mar=c(1, pext, 0, 0))
    a = barplot(xhist$density, axes=FALSE, ylim=c(0, max(xhist$density, xy)),
            space=0) # barplot
    lines(seq(from=0, to=lhist-1, length.out=num.dnorm), xy, col=dcol) # line
    axis(1, at=seq(1, to=nrow(a), length.out=4)-.5, labels=round(seq(from=min(x[,1]), to=max(x[,1]), length.out=4), digits=2))
	if (plot.cor){
		corval = cor(x, use="pairwise.complete.obs", method="spearman")[1,2]
		corval = paste("r=", round(corval, digits=3), sep="")
	    legend("topright", legend=corval, bty="n")
    }
    
    ## barplot and line for y (right)
    par(mar=c(pext, 1, 0, 0), mgp=c(1, .5, 0), tck=-.01, cex.axis=.8)
    b = barplot(yhist$density, axes=FALSE, xlim=c(0, max(yhist$density, yy)),
            space=0, horiz=TRUE) # barplot
    lines(yy, seq(from=0, to=lhist-1, length.out=num.dnorm), col=dcol) # line
    axis(2, at=seq(1, to=nrow(b), length.out=4)-.5, labels=round(seq(from=min(x[,2]), to=max(x[,2]), length.out=4), digits=2))	
	## Set up x axis with tick marks alone
	# axis(1, at = seq(from=1, to=nrow(b), length.out=4), labels = FALSE, tick=T)
	# labels <- round(seq(from=min(x[,2]), to=max(x[,2]), length.out=4), digits=2)
	# text(b[1,1] - 0.51, seq(from=1, to=nrow(b), length.out=4)-1.5, 
			# srt = 90, adj = c(0,0),labels = labels, xpd = TRUE, cex=.8)


    ## restore parameters
    par(par.)
}

```

# Calculation spearman rank correlation between predicted and actual data

```{r}
# Calculating spearman rank correlation 

cor.test(data$X1, data$actual, method="spearman", exact=FALSE)
spearman.plot(data, col="red", lhist=50)
```

# shuffling the data labels and saving predicted column each time for the comparaison  

```{r}
# shuffling the data labels
temp_func <- function(df, name, spl, nr, check){
  if(check=="test"){
    ts <- df$temp_name[(spl+1):nr]
    return(ts)
  }else{
    tr <- df$temp_name[1:spl]
    return(tr)
  }
}
sh_model <- c()
mse_list <- c()
mae_list <- c()
spearman_list <- c()
i <-1
while (i < 101) {
  
  # shuffle the data
  combined_data <- combined_data[sample(nrow(combined_data)),]
  
  # split the data
  nrow <- nrow(combined_data)
  ncol <- ncol(combined_data)
  spliter_8 <- as.integer(nrow*0.8)
  x_train = combined_data[1:spliter_8, 1:(ncol-2)]
  x_test = combined_data[(spliter_8+1):nrow,1:(ncol-2)]
  
  
  temp_train <- temp_func(combined_data, temp_name, spliter_8, nrow, "test")
  temp_train <- temp_func(combined_data, temp_name, spliter_8, nrow, "train")
  
  # best lambda suited to the shuffled data
  lambdas <- 10^seq(2, -3, by = -.1)
  lasso_reg <- cv.glmnet(data.matrix(x_train), amikacin_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 5)
  lambda_best <- lasso_reg$lambda.min 
  
  # adapting the model with the shuffled data
  lasso_model <- glmnet(data.matrix(x_train), amikacin_train, alpha = 1, lambda = lambda_best, standardize = TRUE)
  
  # prediction of x_test to store the predictions
  predictions_test <- predict(lasso_model, s = lambda_best, newx = data.matrix(x_test))
  
  data <- data.frame(pred = predictions_test, actual = amikacin_test)
  mse_list[i] <- mean((data$actual - data$X1)^2)
  #print(mean((data$actual - data$X1)^2))
  mae_list[i] <- mae(data$X1, data$actual)
  #print(mae(data$X1, data$actual))
  spearman_list[i] <- cor.test(data$X1, data$actual, method="spearman", exact=FALSE)$p.value
  #print(cor.test(data$X1, data$actual, method="spearman", exact=FALSE)$p.value)
  sh_model[i] <- paste("Shuffle", as.character(i), sep = " ")
  #print(sh_model[i])
  i <- i+1
}

# Gouping the correlation data generated during shuffles
df <- data.frame( sh_model, mae_list, mse_list, spearman_list)
df

# the value of R-square stayed always negative in all the shuffles, so the model does not fit the data even when shuffling. When can note that the R-square value keeps changing with every shuffle of the data so the model evaluation depends on the observations order.
```

```{r}
set.seed(7)
# load the library
#install.packages("mlbench")
#install.packages("caret")
library(mlbench)
library(caret)
# load the dataset
data(x_train)
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(ofloxacin_train~., data=x_train, method="lvq", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
```
